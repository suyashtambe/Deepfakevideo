{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import LSTM, Dense, TimeDistributed, Flatten, Dropout, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from sklearn.utils import resample\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import MobileNetV2 \n",
    "from tensorflow.keras.applications import EfficientNetB0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fake videos balanced to match the number of real videos.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Define the folder containing the fake videos\n",
    "fake_folder = r'C:\\Users\\Suyash Tambe\\Desktop\\Deepfakevideo\\train_samples\\FAKE'\n",
    "\n",
    "\n",
    "# Get a list of all fake video files\n",
    "fake_videos = os.listdir(fake_folder)\n",
    "\n",
    "# Number of real videos you want to match\n",
    "num_real_videos = 77\n",
    "\n",
    "# If fake videos are more than the real videos, delete excess\n",
    "if len(fake_videos) > num_real_videos:\n",
    "    # Randomly select videos to keep\n",
    "    videos_to_keep = random.sample(fake_videos, num_real_videos)\n",
    "    \n",
    "    # Delete excess videos\n",
    "    for video in fake_videos:\n",
    "        if video not in videos_to_keep:\n",
    "            video_path = os.path.join(fake_folder, video)\n",
    "            os.remove(video_path)\n",
    "            print(f\"Deleted: {video_path}\")\n",
    "\n",
    "print(\"Fake videos balanced to match the number of real videos.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load videos from a folder, resize frames, and limit frames\n",
    "def load_videos_from_folder(folder, frame_limit=100, resize=(199, 199)):\n",
    "    videos = []\n",
    "    for filename in os.listdir(folder):\n",
    "        video_path = os.path.join(folder, filename)\n",
    "        video = cv2.VideoCapture(video_path)\n",
    "        frames = []\n",
    "        count = 0\n",
    "        while video.isOpened() and count < frame_limit:\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            frame = cv2.resize(frame, resize)\n",
    "            frame = frame / 255.0  \n",
    "            frames.append(frame)\n",
    "            count += 1\n",
    "        video.release()\n",
    "        videos.append(np.array(frames, dtype=np.float32)) \n",
    "    return videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Suyash Tambe\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\wrapper.py:27: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">100</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      │    <span style=\"color: #00af00; text-decoration-color: #00af00\">10,544,035</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">TimeDistributed</span>)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">204800</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │   <span style=\"color: #00af00; text-decoration-color: #00af00\">104,858,112</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">131,328</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">257</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ time_distributed                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m100\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      │    \u001b[38;5;34m10,544,035\u001b[0m │\n",
       "│ (\u001b[38;5;33mTimeDistributed\u001b[0m)               │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m204800\u001b[0m)         │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │   \u001b[38;5;34m104,858,112\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │         \u001b[38;5;34m2,048\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │       \u001b[38;5;34m131,328\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │         \u001b[38;5;34m1,024\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │           \u001b[38;5;34m257\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">115,536,804</span> (440.74 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m115,536,804\u001b[0m (440.74 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">111,483,137</span> (425.27 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m111,483,137\u001b[0m (425.27 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,053,667</span> (15.46 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m4,053,667\u001b[0m (15.46 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Define deeper CNN model with adjusted pooling layers\n",
    "def build_deep_cnn(input_shape):\n",
    "    base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    base_model.trainable = False  # Freeze base model layers\n",
    "\n",
    "    cnn_model = Sequential()\n",
    "    \n",
    "    \n",
    "    cnn_model.add(base_model)\n",
    "\n",
    "    # Add more Conv2D layers for depth\n",
    "    cnn_model.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "    cnn_model.add(BatchNormalization())\n",
    "    cnn_model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))  # Use 'same' padding to preserve dimensions\n",
    "    cnn_model.add(Dropout(0.3))\n",
    "    \n",
    "    cnn_model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    cnn_model.add(BatchNormalization())\n",
    "    cnn_model.add(MaxPooling2D(pool_size=(2, 2), padding='same'))\n",
    "    cnn_model.add(Dropout(0.3))\n",
    "\n",
    "    # Adjust pooling size to avoid reducing the dimensions too much\n",
    "    cnn_model.add(Conv2D(512, (3, 3), activation='relu', padding='same'))\n",
    "    cnn_model.add(BatchNormalization())\n",
    "    cnn_model.add(MaxPooling2D(pool_size=(1, 1), padding='same'))  # Smaller pool size\n",
    "    cnn_model.add(Dropout(0.4))\n",
    "\n",
    "    # Add a Flatten layer to prepare for Dense layers\n",
    "    cnn_model.add(Flatten())\n",
    "    \n",
    "    return cnn_model\n",
    "\n",
    "# Build the CNN model for frame-level classification\n",
    "def build_cnn_model(input_shape, sequence_length):\n",
    "    cnn = build_deep_cnn(input_shape)\n",
    "    \n",
    "    model = Sequential()\n",
    "    \n",
    "    # Apply CNN to each frame using TimeDistributed\n",
    "    model.add(TimeDistributed(cnn, input_shape=(sequence_length, *input_shape)))\n",
    "    \n",
    "    # Flatten all frames for final classification\n",
    "    model.add(Flatten())\n",
    "    \n",
    "    # Fully connected layers with increased size and BatchNormalization\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dropout(0.5))\n",
    "    \n",
    "    # Output layer\n",
    "    model.add(Dense(1, activation='softmax'))\n",
    "    \n",
    "    # Compile the model with sgd optimizer and lower learning rate\n",
    "    model.compile(optimizer=Adam(learning_rate=0.00001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "# Load real and fake videos\n",
    "real_videos = load_videos_from_folder(r'C:\\Users\\Suyash Tambe\\Desktop\\Deepfakevideo\\train_samples\\REAL', frame_limit=100, resize=(199, 199))\n",
    "fake_videos = load_videos_from_folder(r'C:\\Users\\Suyash Tambe\\Desktop\\Deepfakevideo\\train_samples\\FAKE', frame_limit=100, resize=(199, 199))\n",
    "\n",
    "# Define parameters\n",
    "sequence_length = 100  # Number of frames in each video\n",
    "frame_shape = (199, 199, 3)  # Frame size\n",
    "batch_size = 32\n",
    "\n",
    "# Build the model (CNN only)\n",
    "cnn_model = build_cnn_model(frame_shape, sequence_length)\n",
    "\n",
    "# Print model summary\n",
    "cnn_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 442s/step - accuracy: 0.5703 - loss: 0.9376    \n",
      "Epoch 1: accuracy improved from -inf to 0.54688, saving model to cnn_deepfake_best.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1930s\u001b[0m 452s/step - accuracy: 0.5625 - loss: 0.9463\n",
      "Epoch 2/6\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 436s/step - accuracy: 0.7188 - loss: 0.6626  \n",
      "Epoch 2: accuracy improved from 0.54688 to 0.71875, saving model to cnn_deepfake_best.keras\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m875s\u001b[0m 442s/step - accuracy: 0.7188 - loss: 0.6711\n",
      "Epoch 3/6\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441s/step - accuracy: 0.5625 - loss: 0.9907  \n",
      "Epoch 3: accuracy did not improve from 0.71875\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m864s\u001b[0m 442s/step - accuracy: 0.5625 - loss: 0.9818\n",
      "Epoch 4/6\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 441s/step - accuracy: 0.5625 - loss: 1.1206  \n",
      "Epoch 4: accuracy did not improve from 0.71875\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m897s\u001b[0m 441s/step - accuracy: 0.5625 - loss: 1.1080\n",
      "Epoch 5/6\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 440s/step - accuracy: 0.4531 - loss: 1.1732  \n",
      "Epoch 5: accuracy did not improve from 0.71875\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m891s\u001b[0m 440s/step - accuracy: 0.4688 - loss: 1.1341\n",
      "Epoch 6/6\n"
     ]
    }
   ],
   "source": [
    "def video_generator(real_videos, fake_videos, batch_size):\n",
    "    while True:\n",
    "        X_batch = []\n",
    "        y_batch = []\n",
    "        for _ in range(batch_size):\n",
    "            # Randomly pick a video from real or fake\n",
    "            if np.random.rand() < 0.5:\n",
    "                idx = np.random.randint(len(real_videos))\n",
    "                X_batch.append(real_videos[idx])\n",
    "                y_batch.append(1)  # Real label\n",
    "            else:\n",
    "                idx = np.random.randint(len(fake_videos))\n",
    "                X_batch.append(fake_videos[idx])\n",
    "                y_batch.append(0)  # Fake label\n",
    "            \n",
    "        X_batch = np.array(X_batch, dtype=np.float32)\n",
    "        y_batch = np.array(y_batch, dtype=np.float32)\n",
    "        yield X_batch, y_batch\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Create the data generator\n",
    "train_gen = video_generator(real_videos, fake_videos, batch_size)\n",
    "\n",
    "# Calculate steps per epoch \n",
    "steps_per_epoch = len(real_videos) // batch_size\n",
    "\n",
    "# Define callback for saving the model\n",
    "model_checkpoint = ModelCheckpoint('cnn_deepfake_best.keras', save_best_only=True, monitor='accuracy', mode='max', verbose=1)\n",
    "\n",
    "# Try-except block to save the model if crash occurs\n",
    "try:\n",
    "    # Train the model using the generator with 6 epochs\n",
    "    cnn_model.fit(train_gen, steps_per_epoch=steps_per_epoch, epochs=6, callbacks=[model_checkpoint])\n",
    "except Exception as e:\n",
    "    print(f\"Training interrupted due to error: {e}\")\n",
    "    # Save model in case of crash\n",
    "    cnn_model.save('cnn_deepfake_interrupted.keras')\n",
    "    print(\"Model saved after interruption.\")\n",
    "else:\n",
    "    # Save the final trained model\n",
    "    cnn_model.save('2_cnn_deepfake_final.keras')\n",
    "    print(\"Training completed and model saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
