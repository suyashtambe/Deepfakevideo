{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your trained model\n",
    "model_path = r'C:\\Users\\Suyash Tambe\\Desktop\\Deepfakevideo\\71%cnn_deepfake_best.keras'  \n",
    "model = load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m225s\u001b[0m 225s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step\n",
      "Deepfake detected at the following frames and timestamps:\n",
      "Frame: 0, Timestamp: 0.00 seconds\n",
      "Frame: 1, Timestamp: 0.03 seconds\n",
      "Frame: 2, Timestamp: 0.07 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the preprocessing function based on your model requirements\n",
    "def preprocess_frame(frame, target_size=(199, 199)):\n",
    "    # Resize the frame to the target input size (e.g., 199x199)\n",
    "    frame_resized = cv2.resize(frame, target_size)\n",
    "    \n",
    "    # Convert from BGR  to RGB if your model expects RGB\n",
    "    frame_rgb = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Normalize the pixel values \n",
    "    frame_normalized = frame_rgb / 255.0\n",
    "    \n",
    "    return frame_normalized\n",
    "\n",
    "# Function to detect deepfake frames and their timestamps\n",
    "def detect_deepfake_frames(frame_predictions, fps=30):\n",
    "    deepfake_frames = []\n",
    "    \n",
    "    # Go through the frame-level predictions\n",
    "    for i, pred in enumerate(frame_predictions):\n",
    "        if pred > 0.5:  # Assuming threshold of 0.5 for detecting fake\n",
    "            timestamp = i / fps  # Calculate timestamp based on frame rate (fps)\n",
    "            deepfake_frames.append((i, timestamp))  # Record frame index and timestamp\n",
    "            \n",
    "    return deepfake_frames\n",
    "\n",
    "# Inference function to predict on a single video and detect frames\n",
    "def predict_deepfake_on_video(video_path, model, sequence_length=100, fps=30):\n",
    "    # Open the video using OpenCV\n",
    "    video_capture = cv2.VideoCapture(video_path)\n",
    "    frame_predictions = []\n",
    "    \n",
    "    # Initialize a list to hold the sequence of frames\n",
    "    frame_sequence = []\n",
    "\n",
    "    while video_capture.isOpened():\n",
    "        ret, frame = video_capture.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Preprocess the frame as required by your model\n",
    "        preprocessed_frame = preprocess_frame(frame)\n",
    "        frame_sequence.append(preprocessed_frame)\n",
    "        \n",
    "        # Check if we have enough frames to form a sequence \n",
    "        if len(frame_sequence) == sequence_length:\n",
    "            # Convert frame sequence to a numpy array and add batch dimension\n",
    "            frame_sequence_array = np.expand_dims(np.array(frame_sequence), axis=0)  # Shape: (1, 100, 199, 199, 3)\n",
    "            \n",
    "            # Predict on the sequence of frames\n",
    "            preds = model.predict(frame_sequence_array)[0]  # Get predictions for all 100 frames\n",
    "            frame_predictions.extend(preds)\n",
    "            \n",
    "            # Clear the frame sequence to start accumulating the next batch\n",
    "            frame_sequence = []\n",
    "    \n",
    "    # Release video capture\n",
    "    video_capture.release()\n",
    "    \n",
    "    # Get the frames where deepfake is detected\n",
    "    deepfake_frames = detect_deepfake_frames(frame_predictions, fps=fps)\n",
    "    \n",
    "    if deepfake_frames:\n",
    "        print(f\"Deepfake detected at the following frames and timestamps:\")\n",
    "        for frame, timestamp in deepfake_frames:\n",
    "            print(f\"Frame: {frame}, Timestamp: {timestamp:.2f} seconds\")\n",
    "    else:\n",
    "        print(\"No deepfake detected in this video.\")\n",
    "        \n",
    "    return deepfake_frames\n",
    "\n",
    "\n",
    "video_path = r'C:\\Users\\Suyash Tambe\\Desktop\\Deepfakevideo\\train_samples\\FAKE\\bbhpvrmbse.mp4'  \n",
    "fps = 30  # Set your video's frames per second\n",
    "\n",
    "# Make predictions and detect deepfake frames\n",
    "detected_frames = predict_deepfake_on_video(video_path, model, sequence_length=100, fps=fps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
